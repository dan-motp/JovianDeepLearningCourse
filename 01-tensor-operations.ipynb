{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tensors - simple matrix operations and attributes\n",
    "\n",
    "### Apart from the transpose, more matrix operations and attributes are presented here.\n",
    "\n",
    "Some of the most commonly used operations in linear algebra, these are essential to \"characterize\" your matrix and its properties. \n",
    "- torch.inverse()\n",
    "- torch.det()\n",
    "- torch.matrix_rank()\n",
    "- torch.diag()\n",
    "- torch.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 - __[torch.inverse(input, out=None)](https://pytorch.org/docs/stable/torch.html#torch.inverse)__\n",
    "\n",
    "A square matrix A of order <i>n</i> is said to be <i>invertible</i> if there is another square matrix B, in which:\n",
    "\n",
    "$$AB = BA = I_{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [2., 3.]])\n",
      "tensor([[-3.,  2.],\n",
      "        [ 2., -1.]])\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "A = torch.tensor([[1., 2.], [2., 3.]])\n",
    "print(A)\n",
    "\n",
    "B = torch.inverse(A)\n",
    "print(B)\n",
    "\n",
    "print(torch.mm(A, B))\n",
    "\n",
    "# We could also compare our multiplication with an identity matrix of order n:\n",
    "# The @ operator denotes matrix multiplication and torch.eye(2) is a 2x2 Identity matrix\n",
    "(A @ torch.inverse(A)) == torch.eye(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the square matrix A, we calculated its inverse (matrix B), and by multiplying them we got a resulting matrix that is, as we wanted to prove, an identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 17.0001, -12.0001],\n",
      "        [-24.0002,  17.0001]])\n",
      "tensor([[ 17., -12.],\n",
      "        [-24.,  17.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [False, False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "C = torch.tensor([[3., 2.],\n",
    "                  [4., 3.]])\n",
    "\n",
    "D = torch.tensor([[3., 2.],\n",
    "                  [4., 3.]])\n",
    "\n",
    "M = C @ D\n",
    "Mi = torch.inverse(M)\n",
    "print(Mi)\n",
    "\n",
    "Ci = torch.inverse(C)\n",
    "Di = torch.inverse(D)\n",
    "print(Ci @ Di)\n",
    "\n",
    "# Since both tensors C and D are the same, we can very well expect that their product\n",
    "# will be invertible as well. However, if we had used a comparison operator,\n",
    "# the output would be False, which is due to the decimal precision difference in both operations\n",
    "torch.inverse(M) == torch.inverse(C) @ torch.inverse(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, if we're given two matrices C and D (both of order n), then torch.mm(C, D) is invertible and:\n",
    "\n",
    "$$(CD)^{⁻1} = C^{-1}D^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inverse_cpu: U(2,2) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-283957296c26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inverse_cpu: U(2,2) is zero, singular U."
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "E = torch.tensor([[1., 0.], [1., 0.]])\n",
    "print(E)\n",
    "\n",
    "F = torch.inverse(E)\n",
    "print(F)\n",
    "\n",
    "torch.mm(E, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix E is not invertible, so it's not possible to calculate its inverse and generates a RuntimeError: inverse_cpu: U(2,2) is zero, singular U."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A system of linear equations, such as $$Ax = b$$ will be possible and determinate (it has a single, unique solution), if its coefficient matrix A is invertible, and its determinant is non-null. Being the case, the solution for x will be: $$x = A^{-1}b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - __[torch.det()](https://pytorch.org/docs/stable/torch.html#torch.det)__\n",
    "\n",
    "A matrix is only invertible, if and only if its determinant is non-null. \n",
    "If you consider a square matrix *A = [[a, b], [c, d]]* and assume *a* is non-null, and apply the Gaussian algorithm, you will reach the conclusion that the determinant can be calculated as *ad-bc != 0*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "A = torch.tensor([[1., 2.], [2., 3.]])\n",
    "torch.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previous matrix A, that we know is invertible, its determinant will be:\n",
    "$$1 \\times 3 - 2 \\times 2 = -1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(80.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "G = torch.tensor([[3., 2., 6.],\n",
    "                  [5., 3., 2.],\n",
    "                  [1., 4., 2.]])\n",
    "torch.det(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *n=3* tensors, the determinant can be calculated by somewhat \"extending\" the matrix on its right, by its first *n-1* columns, and adding same direction diagonals:\n",
    "\n",
    "$$|A| = a_{11} a_{22} a_{33} + a_{12} a_{23} a_{31} + a_{13}  a_{21} a_{32}\n",
    "−a_{11} a_{23} a_{32} − a_{12} a_{21} a_{33} − a_{13} a_{22} a_{31}$$\n",
    "\n",
    "\n",
    "$$3 \\times 3 \\times 2 + 2 \\times 2 \\times 1 + 6 \\times 5 \\times 4 -\n",
    "3 \\times 2 \\times 4 - 2 \\times 5 \\times 2 + 6 \\times 3 \\times 1 = 80$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1532, -0.1306],\n",
      "        [ 0.5086, -0.4279],\n",
      "        [-1.9572,  0.1699]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A must be batches of square matrices, but they are 2 by 3 matrices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f8449866a73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: A must be batches of square matrices, but they are 2 by 3 matrices"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "H = torch.randn(3,2)\n",
    "print(H)\n",
    "torch.det(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from the documentation, that a square matrix is necessary to calculate *det()*. If the input tensor is not square then Pytorch will output: \"RuntimeError: A must be batches of square matrices\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on determinants:\n",
    "- If $A_{n \\times n}$ has one null row or null column then $|A|=0$\n",
    "- $|A| = |A^{T}|$\n",
    "- If $A$ is triangular (inferior or superior) then $|A| = \\prod_{i=1,..,n}(A)_{ii}$\n",
    "\n",
    "The determinant tells us things about the matrix that are useful in systems of linear equations, helps us find the inverse of a matrix, is useful in calculus and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - __[torch.matrix_rank(input, tol=None, symmetric=False)](https://pytorch.org/docs/stable/torch.html#torch.matrix_rank)__\n",
    "\n",
    "The rank of a matrix A is the dimension of the vector space generated  by its columns and corresponds to the maximum number of linearly independent columns of A. It's usually represented by *car(A)*, *c(A)* or *rank(A)*. In PyTorch it is calculated by torch.matrix_rank(A).\n",
    "Specifically, it's equal to the number of pivots obtained by Gaussian Elimination Algorithm to matrix A. It denotes the number of non-null lines of the corresponding triangular matrix U , and *rank(A) = rank(U)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "I = torch.tensor([[3., 0., 7.],\n",
    "                  [5., 0., 2.],\n",
    "                  [3., 0., 2.]])\n",
    "torch.matrix_rank(I)\n",
    "# torch.inverse(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since tensor I has a null column, we can check that *rank(I) < n* and that it is not invertible.\n",
    "The same would occur if it had a null row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "J = torch.tensor([[3., 3., 7.],\n",
    "                  [5., 1., 4.],\n",
    "                  [4., 8., 3.]])\n",
    "torch.matrix_rank(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor J has *rank(J) = n*, so it is invertible and has *det(J) != 0*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5474,  1.6583, -0.3952])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "matrix_rank(Float{[3]}): expected a 2D tensor of floating types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3ab369558a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: matrix_rank(Float{[3]}): expected a 2D tensor of floating types"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "K = torch.randn(3)\n",
    "print(K)\n",
    "torch.matrix_rank(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only break error I could find was when you input a non 2D tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A square matrix A of n-order is said to be non-singular if *rank(A)=n*, and if *rank(A) < rank(A|b)* then the linear system of *Ax=b* is said to be an impossible system. Furthermore, a possible system is determined *rank(A) = rank(A|b)* if, and only if, there are no free variables, that is, if the number of pivots are exactly the same to the number of incognite variables and so *rank(A) = rank(A|b) = n*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - __[torch.diag(input, diagonal=0, out=None)](https://pytorch.org/docs/stable/torch.html#torch.diag)__\n",
    "\n",
    "\n",
    "If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal.    If input is a matrix (2-D tensor), then returns a 1-D tensor with the diagonal elements of input.\n",
    "\n",
    "The argument diagonal controls which diagonal to consider:\n",
    "If diagonal = 0, it is the main diagonal.\n",
    "If diagonal > 0, it is above the main diagonal.\n",
    "If diagonal < 0, it is below the main diagonal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2320,  0.9977, -0.4161],\n",
      "        [-1.6745, -1.4483, -0.9491],\n",
      "        [-0.0571, -0.9602, -0.0216]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2320, -1.4483, -0.0216])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "L = torch.randn(3,3)\n",
    "print(L)\n",
    "torch.diag(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal of matrix L is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0860, -0.2763,  1.6309])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0860,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.2763,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.6309],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "M = torch.randn(3)\n",
    "print(M)\n",
    "torch.diag(M, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation about example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False,  True]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "_th_diag not supported on CPUType for Bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7773687f19a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m ], dtype=torch.bool)\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_diag not supported on CPUType for Bool"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "M = torch.tensor([\n",
    "    [True, False, False],\n",
    "    [False, False, False],\n",
    "    [False, False, True]\n",
    "], dtype=torch.bool)\n",
    "print(M)\n",
    "torch.diag(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the input matrix is of boolean type, it will result in the above error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - __[torch.reshape(input, shape)](https://pytorch.org/docs/stable/torch.html#torch.reshape)__\n",
    "\n",
    "Returns the same elements of the input matrix, but in a different shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0905, -0.4917,  0.0684,  1.4956],\n",
       "        [ 0.3972, -0.3935, -0.1450, -0.6096],\n",
       "        [ 0.8338,  1.2405,  1.6513,  0.0353],\n",
       "        [ 1.4410, -0.8317,  1.3719, -2.0732]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "N = torch.randn(8,2)\n",
    "torch.reshape(N, (4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "2\n",
      "tensor([0, 1, 2, 3])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "O = torch.tensor([[0, 1], [2, 3]])\n",
    "print(O)\n",
    "print(O.dim())\n",
    "\n",
    "P = torch.reshape(O, (-1,))\n",
    "print(P)\n",
    "print(P.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use (-1,) as shape to \"flatten\" tensor O, from the documentation: \"A single dimension may be -1, in which case it’s inferred from the remaining dimensions and the number of elements in input\". It's interesting to check the matrix dimension change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 2]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-fcc17296ec2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 2]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "Q = torch.randn(3,3)\n",
    "torch.reshape(Q, (4,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're not able to reshape a matrix if their number of elements are not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape will be a commonly used function, as well as the view() and squeeze() functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This was mere attempt to address some simple tensor attributes/functions, which I believed to be common in linear algebra operations.\n",
    "\n",
    "If any assertations are incorrect, I would very much appreciate your contact for correction.\n",
    "\n",
    "This assignment is part of the DeepLearning: Zero to GANs course from Jovian.ml and FreeCodeCamp.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "* https://towardsdatascience.com/pytorch-fundamentals-50af6121d4a3\n",
    "* https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be\n",
    "* https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://towardsdatascience.com/pytorch-for-deep-learning-a-quick-guide-for-starters-5b60d2dbb564\n",
    "* https://medium.com/quantyca/pytorch-tips-and-tricks-from-tensors-to-neural-networks-febc73b3e34c\n",
    "* https://www.kdnuggets.com/2018/11/introduction-pytorch-deep-learning.html\n",
    "* https://towardsdatascience.com/how-to-train-your-neural-net-tensors-and-autograd-941f2c4cc77c\n",
    "* https://www.datacamp.com/community/tutorials/investigating-tensors-pytorch\n",
    "* https://deeplizard.com/learn/video/fCVuiW9AFzY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/dan-motp/01-tensor-operations-79c2d\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/dan-motp/01-tensor-operations-79c2d'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
